{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hertie-School-Machine-Learning-F2022/git-github-assignment-and-fundamentals-Radwa-Radwan/blob/main/Copy_of_problem_set_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem set 1\n",
        "\n",
        "## Student name: \n",
        "\n",
        "## Submit by: Thursday 22.09.2022, 23:59\n",
        "\n",
        "#### You will go over some of the things that we saw in class today, and will answer the quiz based on the outcome of your computational process. You also need to submit the script to demostrate the process you used to get to the answers.\n",
        "\n",
        "For this problem set you DO NOT NEED to set training and testing data."
      ],
      "metadata": {
        "id": "GFFALBB_XSwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1."
      ],
      "metadata": {
        "id": "OwR7wci3YAKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.datasets import load_diabetes and set X and y\n",
        "from sklearn import datasets\n",
        "from sklearn.datasets import load_diabetes\n",
        "\n",
        "\n",
        "# Take some time to understand the dataset\n",
        "# take a look at it as a DataFrame object\n",
        "\n",
        "\n",
        "# For this problem DO NOT SET training and testing data. We will use the same data\n",
        "# throughout the problem set."
      ],
      "metadata": {
        "id": "7nGQZ9YXhkrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = datasets.load_diabetes(return_X_y = True, as_frame = True)"
      ],
      "metadata": {
        "id": "UZrlPMoA3osz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "ZMGDx8uZ-OY3",
        "outputId": "93439bf4-095c-466f-bfd0-fe26d2033836",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          age       sex       bmi        bp        s1        s2        s3  \\\n",
              "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
              "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
              "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
              "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
              "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
              "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
              "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
              "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
              "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
              "\n",
              "           s4        s5        s6  \n",
              "0   -0.002592  0.019908 -0.017646  \n",
              "1   -0.039493 -0.068330 -0.092204  \n",
              "2   -0.002592  0.002864 -0.025930  \n",
              "3    0.034309  0.022692 -0.009362  \n",
              "4   -0.002592 -0.031991 -0.046641  \n",
              "..        ...       ...       ...  \n",
              "437 -0.002592  0.031193  0.007207  \n",
              "438  0.034309 -0.018118  0.044485  \n",
              "439 -0.011080 -0.046879  0.015491  \n",
              "440  0.026560  0.044528 -0.025930  \n",
              "441 -0.039493 -0.004220  0.003064  \n",
              "\n",
              "[442 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0a9077b-d068-4fbb-9c03-db74c9dcac36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>-0.043401</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.019908</td>\n",
              "      <td>-0.017646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>0.074412</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.068330</td>\n",
              "      <td>-0.092204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005671</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>-0.032356</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.089063</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>-0.036038</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>-0.009362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.031991</td>\n",
              "      <td>-0.046641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.019662</td>\n",
              "      <td>0.059744</td>\n",
              "      <td>-0.005697</td>\n",
              "      <td>-0.002566</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.031193</td>\n",
              "      <td>0.007207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>-0.005515</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>-0.067642</td>\n",
              "      <td>0.049341</td>\n",
              "      <td>0.079165</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>-0.018118</td>\n",
              "      <td>0.044485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>0.017282</td>\n",
              "      <td>-0.037344</td>\n",
              "      <td>-0.013840</td>\n",
              "      <td>-0.024993</td>\n",
              "      <td>-0.011080</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>0.015491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.016318</td>\n",
              "      <td>0.015283</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.026560</td>\n",
              "      <td>0.044528</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.073030</td>\n",
              "      <td>-0.081414</td>\n",
              "      <td>0.083740</td>\n",
              "      <td>0.027809</td>\n",
              "      <td>0.173816</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.004220</td>\n",
              "      <td>0.003064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442 rows Ã— 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0a9077b-d068-4fbb-9c03-db74c9dcac36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0a9077b-d068-4fbb-9c03-db74c9dcac36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0a9077b-d068-4fbb-9c03-db74c9dcac36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How many variables are in X?"
      ],
      "metadata": {
        "id": "gJM0RWChiDJh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2"
      ],
      "metadata": {
        "id": "gnYj7rp4YC85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the SGD Linear Regression algorithm \n",
        "# SGD stands for Stochastic Gradient Descent: the gradient of the loss is \n",
        "# estimated each sample at a time and the model is updated along the way \n",
        "# with a decreasing strength schedule (aka learning rate).\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "# Set it as the mod variable\n",
        "mod = SGDRegressor\n",
        "\n",
        "# Take a look at the parameters\n"
      ],
      "metadata": {
        "id": "A-3u3_nsYEfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "pipe = Pipeline([('model', SGDRegressor()) \n",
        "                 ])\n",
        "pipe.get_params()"
      ],
      "metadata": {
        "id": "LCa1qhdTCgBx",
        "outputId": "2b22f4ca-047c-424d-dc65-f6bb3c66ad3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'memory': None,\n",
              " 'steps': [('model', SGDRegressor())],\n",
              " 'verbose': False,\n",
              " 'model': SGDRegressor(),\n",
              " 'model__alpha': 0.0001,\n",
              " 'model__average': False,\n",
              " 'model__early_stopping': False,\n",
              " 'model__epsilon': 0.1,\n",
              " 'model__eta0': 0.01,\n",
              " 'model__fit_intercept': True,\n",
              " 'model__l1_ratio': 0.15,\n",
              " 'model__learning_rate': 'invscaling',\n",
              " 'model__loss': 'squared_error',\n",
              " 'model__max_iter': 1000,\n",
              " 'model__n_iter_no_change': 5,\n",
              " 'model__penalty': 'l2',\n",
              " 'model__power_t': 0.25,\n",
              " 'model__random_state': None,\n",
              " 'model__shuffle': True,\n",
              " 'model__tol': 0.001,\n",
              " 'model__validation_fraction': 0.1,\n",
              " 'model__verbose': 0,\n",
              " 'model__warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the parameters of the Linear Regression model?"
      ],
      "metadata": {
        "id": "fvzKrAsDjrw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3."
      ],
      "metadata": {
        "id": "zSB12OsWYE6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Standard Scaler and take a look at the parameters\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scal_pipe=Pipeline([('scalar', StandardScaler()) \n",
        "                 ])\n",
        "scal_pipe.get_params()"
      ],
      "metadata": {
        "id": "Abs9a_v8YFYx",
        "outputId": "0c6d1090-b17a-4ec1-ad43-940426d81f78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'memory': None,\n",
              " 'steps': [('scalar', StandardScaler())],\n",
              " 'verbose': False,\n",
              " 'scalar': StandardScaler(),\n",
              " 'scalar__copy': True,\n",
              " 'scalar__with_mean': True,\n",
              " 'scalar__with_std': True}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the default option at which with_mean and with_std are set?"
      ],
      "metadata": {
        "id": "fk3CtAdKkNr2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4."
      ],
      "metadata": {
        "id": "GiVldJW2YFp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline using the two previous steps, for the model\n",
        "# set the SGDRegressor parameter random_state = 123 to reproduce results.\n",
        "mod_pipe = Pipeline([('scaler', StandardScaler()),     \n",
        "                 ('model', SGDRegressor()),\n",
        "                 ])\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "cv=KFold(n_splits=3, random_state=123, shuffle=True)\n",
        "\n",
        "\n",
        "#Fit and predict the pipe, print results\n",
        "\n",
        "mod_pipe.fit(X,y)\n",
        "pred = mod_pipe.predict(X)\n",
        "print(pred)"
      ],
      "metadata": {
        "id": "lzkAXHECYF-B",
        "outputId": "26455e56-31b3-45c6-e72d-834f720b4a42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[202.79550399  70.79521749 173.32848824 164.54910919 128.40207414\n",
            " 105.54592288  78.44221218 122.78308662 158.93833966 214.4106665\n",
            " 100.43244625 105.53514961 114.44481772 161.25002277 101.67212498\n",
            " 174.93676954 208.60436018 181.58167405 146.511218   122.0086688\n",
            " 117.85559829  91.30251447 118.81418254 275.60289978 164.19585442\n",
            " 144.94425433  95.84395411 177.20627255 126.76442763 181.02905746\n",
            " 159.45220281  68.92492819 255.42282768 105.35125046  80.63001509\n",
            "  82.00588869 206.13304884 153.6043839  243.49373193 135.07110519\n",
            " 153.02714783  73.73218318 143.19485837  78.27561251 217.09718437\n",
            " 123.35141277 139.78176849 106.74455015  77.03003843 185.86474277\n",
            " 156.6459567  166.07753898 134.19832912 157.80499126 141.47157836\n",
            "  74.60778643 204.79317425  79.22406217  94.56266487 133.34382823\n",
            " 114.66164615 175.17227301  67.52030114 101.57701521 111.00211472\n",
            " 185.63873182 144.99952175 123.07284809 111.60376583 123.06965911\n",
            "  76.27673611 235.2171401  148.22791085 122.80053746 149.28107621\n",
            " 125.36742246 189.38574902  83.09915175 162.47788864  96.48822251\n",
            " 172.4371743  120.39832778  67.57508935 150.19361429  58.13968072\n",
            " 168.92987336  52.76512816 150.16506441  79.2749119  104.4102119\n",
            "  84.15734115 186.97084977 187.58344013  60.47629281 107.04741436\n",
            " 122.2873754  206.0674981  213.46546477 122.22280228 135.87891032\n",
            " 167.24404637 105.61391923 150.16395948 159.10285469 157.31223056\n",
            " 113.14973133  76.22063187 159.74985522 225.99749427 143.34576436\n",
            "  52.17096395 121.13618849 153.37123643 206.59842764 299.5164542\n",
            " 192.06133693 210.45804223 237.299183   163.64161177 146.25043021\n",
            " 156.8654278  197.43145448 218.03679008 173.90312918 166.6855002\n",
            " 189.72913398  66.40747962 105.58810345  92.94488638 207.79479396\n",
            " 242.5234571   72.55329868 113.6274889   71.837067   141.36583651\n",
            " 236.18389335  61.42209079 231.39395288 250.98611921 250.81415995\n",
            " 156.80587394 227.14798536 170.80208745 118.73078856 176.36726401\n",
            " 238.92087037 188.80249262 227.12097856 116.21814303 175.53083874\n",
            " 208.29270159 141.3541364  196.6773758  122.13499592 149.06894271\n",
            " 199.56121403 144.65417491 122.33506856  86.14892849 233.85202605\n",
            "  83.68341418 236.76696013 144.03325126 196.54896503 140.95812176\n",
            "  77.67169366  64.29998536 265.12811088 225.94436828 244.4033707\n",
            "  55.26047982  89.96125417 223.86084632  94.02427613 159.8028872\n",
            " 119.28219823 156.16856101 223.72537809 101.80226427 164.43419809\n",
            " 176.0062051   90.39657138 170.38958127 154.75068283 198.84934705\n",
            " 186.34371788 195.29673564  72.25180355 153.97485413 113.94998383\n",
            " 191.68301047 123.92427958  92.57228346 140.1735238  151.7017659\n",
            " 168.70400688  99.11003434 187.07518822 149.72571263 182.02621336\n",
            "  96.00661186  71.54400179 171.47882047 195.04925437 174.012383\n",
            " 226.56523186 158.47329417 211.07045964 220.5203129  169.85523061\n",
            " 127.52155345 174.80104278 150.68337274  98.18231621  95.90609078\n",
            " 259.57218249 219.37979837 219.67940794 130.53421904 140.13719986\n",
            "  63.2888375  140.24248021 150.83473598 122.23802001  77.38790467\n",
            " 228.37559117  79.22659452 104.17381078 117.50496913  98.65363581\n",
            " 170.39908642 156.17040987 156.31484859 140.85449186 231.02103055\n",
            " 172.91019629 185.90095134  67.21965126 184.8596998  180.60757679\n",
            " 231.38962667 120.07204413  91.17628818 101.02525566 140.67501823\n",
            " 101.41996826 119.96602475  79.09436119 236.75285551 247.23303227\n",
            " 265.16357985 278.64734297 180.16031876 202.00417691 270.13780384\n",
            " 114.87269727 265.15140545 100.6698488  116.49790437 142.45204821\n",
            "  62.05529554 122.92971222 260.99016399  50.39979924 128.33277767\n",
            " 128.11984235  39.98230742 137.60791503 240.88695698  85.44431408\n",
            " 187.64353194 162.7683464  145.57356876 203.25244132 173.18735436\n",
            " 154.91508895 191.54264034 112.26129872 109.49311768 115.53014019\n",
            " 162.32370872  92.87575213 140.30786973  88.12967374 156.38787584\n",
            " 199.35982007  72.89344773 148.03418583  85.50888965 192.32300702\n",
            " 218.75306578 205.31293959  93.85382772 184.79875335  89.55949022\n",
            " 151.29562378  78.8093834  102.91795276 105.47275044 122.01768424\n",
            " 216.27851246 124.76332254 204.86722015 233.11675814 123.94529511\n",
            " 131.17881066 128.01200646 145.76521993  89.13518246 138.66978079\n",
            " 203.73198308 171.65366063 124.35424452 212.30019488 173.20056506\n",
            " 109.3176762  198.87404362 171.91544382 159.57373578 186.58652733\n",
            " 190.39395672 289.91285698 298.92202244 235.70135194 210.17255578\n",
            " 221.70984887 153.26751654 222.48241096 186.12711044 101.29815985\n",
            " 177.55287366 111.2153484  290.03499415 179.21210723  82.27817102\n",
            "  87.63205756 252.55185382 170.60004767 123.36918053 146.29482036\n",
            " 171.5052827  183.90598681 164.34205675 161.22972335 143.68517035\n",
            " 123.90582111 181.47519913 100.69619742 127.24137772  97.18571323\n",
            " 250.66035092  87.83517276  54.38950375 181.43318806 198.12233338\n",
            " 132.93996981  93.18583067 200.32070726  58.64931912 171.00244763\n",
            " 193.14835928 122.8758535  232.04081339 160.69204805 156.65611243\n",
            " 159.69209223 255.98469132 256.02117158 201.09781613 182.65018264\n",
            "  60.66481102 210.69512506 108.19994529 142.3632365  124.18429889\n",
            " 176.68610274 212.90344793 166.75181052 161.4544451  134.30985417\n",
            " 176.47634124  72.23968374 256.44602463 112.62960692 111.9155516\n",
            " 137.20846748 108.5259796  103.21416133 159.9196319   75.81799018\n",
            " 264.28102079  60.20731822 100.8061009  101.69367283 279.2331253\n",
            " 166.28319904  69.96661302 178.20376462 171.61586496 187.80419562\n",
            " 184.51462615  86.53160066 143.64065484 251.72295693 199.36266528\n",
            " 278.10838009  52.48368741 176.69780898 202.82224111 172.11431151\n",
            " 159.67585095 152.94201223 230.15707152 122.78893381 165.73608806\n",
            " 169.51904095 227.75529498 152.9106035  100.47748569  84.4548132\n",
            " 141.0794019  189.97595556 200.16772721 150.09083966 168.0349191\n",
            " 108.0386127  160.83576966 130.17812341 258.93233621 101.80106333\n",
            " 114.92004158 118.33792099 218.72098141  61.49753827 134.1693489\n",
            " 120.97924458  54.24803661 190.8377331  103.07224079 123.16238899\n",
            " 210.38521811  47.79894307]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the first 4 predicted values? "
      ],
      "metadata": {
        "id": "m8_OvAAalaWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5."
      ],
      "metadata": {
        "id": "u7GHpq7FYGQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now create a GridSearchCV Object using the previous pipe object,\n",
        "# where the parameter 'model__alpa' is set to try 0.0001, 0.005, 0.001.\n",
        "# Set cross validation to 3 times.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "mod2 = GridSearchCV(estimator=mod_pipe,\n",
        "                 param_grid={\n",
        "                   'model__alpha': ['0.0001', '0.005', '0.001'],       \n",
        "                 },\n",
        "                 cv=cv)\n"
      ],
      "metadata": {
        "id": "DFbW7-gPYGjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How are you supposed to write the values of the parameter 'alpha'?"
      ],
      "metadata": {
        "id": "qCUnrjFJnY-X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6."
      ],
      "metadata": {
        "id": "2EN6DfL2YHCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now fit the GridSearch model from above and see the results \n",
        "# (Hint: to make sure we all get the same results, you had to use the pipe that\n",
        "# was set in question 4 making sure we used the same random_state = 123)\n",
        "mod2.fit(X,y)\n",
        "\n"
      ],
      "metadata": {
        "id": "46sNANbrYHdb",
        "outputId": "7da534a3-ff40-4f71-ca0e-d5777f07144a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "9 fits failed out of a total of 9.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1546, in fit\n",
            "    sample_weight=sample_weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py\", line 1472, in _fit\n",
            "    self._validate_params()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py\", line 141, in _validate_params\n",
            "    if not isinstance(self, SGDOneClassSVM) and self.alpha < 0.0:\n",
            "TypeError: '<' not supported between instances of 'str' and 'float'\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [nan nan nan]\n",
            "  category=UserWarning,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-8c2e7072cb24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# (Hint: to make sure we all get the same results, you had to use the pipe that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# was set in question 4 making sure we used the same random_state = 123)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmod2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m   1544\u001b[0m             \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1547\u001b[0m         )\n\u001b[1;32m   1548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m     ):\n\u001b[0;32m-> 1472\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarm_start\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcoef_init\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py\u001b[0m in \u001b[0;36m_validate_params\u001b[0;34m(self, for_partial_fit)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"l1_ratio must be in [0, 1]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDOneClassSVM\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alpha must be >= 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_no_change\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which is the best model? Look at the rank_test_value"
      ],
      "metadata": {
        "id": "byN7vPtHon9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7.\n",
        "\n",
        "Find out which test score is the one that is reported above in mean_test_score. What is it and how do you interpret this results?"
      ],
      "metadata": {
        "id": "u1uts1sGYHwM"
      }
    }
  ]
}